/*
  ==============================================================================

	This file was auto-generated by the Introjucer!

	It contains the basic framework code for a JUCE plugin processor.

  ==============================================================================
*/

#include "RNBO_JuceAudioProcessor.h"
#include "RNBO_JuceAudioProcessorEditor.h"
#include "RNBO_JuceAudioProcessorUtils.h"

#if JUCE_TARGET_HAS_BINARY_DATA
#include "BinaryData.h"
#endif
namespace RNBO {

class FloatParameter : public AudioProcessorParameter
{
	using String = juce::String;
public:

	FloatParameter (ParameterIndex index, CoreObject& rnboObject)
	:
		AudioProcessorParameter()
	, _index(index)
	, _rnboObject(rnboObject)
	{
	}

	float getValue() const override
	{
		// getValue wants the value between 0 and 1
		float normalizedValue = (float)_rnboObject.getParameterNormalized(_index);
		return normalizedValue;
	}

	void setValue (float newValue) override
	{
		jassert(newValue >= 0 && newValue <= 1.);	// should be getting normalized values
		float oldValue = getValue();
		if (newValue != oldValue) {
			_rnboObject.setParameterValueNormalized(_index, newValue);
		}
	}

	float getDefaultValue() const override
	{
		ParameterInfo info;
		_rnboObject.getParameterInfo(_index, &info);
		return static_cast<float>(_rnboObject.convertToNormalizedParameterValue(_index, info.initialValue));
	}

	/*
	 * exists in newer JUCE with HostedAudioProcessorParameter
	String getParameterID() const override
	{
		return String(_rnboObject.getParameterId(_index));
	}
	*/

	String getName (int maximumStringLength) const override
	{
		return (String(_rnboObject.getParameterId(_index))).substring(0, maximumStringLength);
	}

	String getLabel() const override
	{
		return String();
	}

	float getValueForText (const String& text) const override
	{
		// this is never called
		// does it want the normalized value or not?
		// we probably should convert to normalized since getText() expects to get a normalized value
		// but I guess it doesn't matter if this is never called.
		return text.getFloatValue();
	}

	String getText (float value, int maximumStringLength) const override
	{
		// we want to print the normalized value
		float displayValue = (float)_rnboObject.convertFromNormalizedParameterValue(_index, value);
		return AudioProcessorParameter::getText(displayValue, maximumStringLength);
	}

protected:
	ParameterIndex			_index;
	CoreObject&				_rnboObject;
};

class EnumParameter : public FloatParameter
{
	using String = juce::String;
public:

	EnumParameter (ParameterIndex index, Index steps, const char** enumValues,  CoreObject& rnboObject)
	: FloatParameter(index, rnboObject)
	{
		for (Index i = 0; i < steps; i++) {
			_enumValues.push_back(enumValues[i]);
		}
	}

	String getText (float value, int maximumStringLength) const override
	{
		RNBO_UNUSED(maximumStringLength)
		// we want to print the normalized value
		long displayValue = (long)_rnboObject.convertFromNormalizedParameterValue(_index, value);
		String v;
		if (displayValue >= 0 && static_cast<Index>(displayValue) < _enumValues.size()) {
			v = _enumValues[static_cast<Index>(displayValue)];
		}
		return v.substring(0, maximumStringLength);
	}

private:
	Vector<String>		_enumValues;
};

//==============================================================================

JuceAudioProcessor::BusesProperties JuceAudioProcessor::makeBusesPropertiesForRNBOObject(RNBO::CoreObject &object)
{
	auto bp = BusesProperties();
	if (object.getNumInputChannels() > 0)
		bp.addBus(true, "Input", juce::AudioChannelSet::canonicalChannelSet((int) object.getNumInputChannels()), true);
	if (object.getNumOutputChannels() > 0)
		bp.addBus(false, "Output", juce::AudioChannelSet::canonicalChannelSet((int) object.getNumOutputChannels()), true);
	return bp;
}

JuceAudioProcessor::JuceAudioProcessor()
	: CoreObjectHolder(this)
	, AudioProcessor(
#ifdef PLUGIN_BUSES_PROPERTIES
		PLUGIN_BUSES_PROPERTIES
#else
		JuceAudioProcessor::makeBusesPropertiesForRNBOObject(_rnboObject)
#endif
	)
	, _presetList(nullptr)
	, _datarefList(nullptr)
	, _syncEventHandler(*this)
	, _currentPresetIdx(-1)
{
	int juceIndex = 0;
	for (ParameterIndex i = 0; i < _rnboObject.getNumParameters(); i++) {
		ParameterInfo info;
		_rnboObject.getParameterInfo(i, &info);
		if (info.visible) {
			_rnboParamIndexToJuceParamIndex.insert({i, juceIndex++});
			if (info.enumValues && info.steps > 0) {
				addParameter(new EnumParameter(i, static_cast<Index>(info.steps), info.enumValues, _rnboObject));
			}
			else {
				addParameter(new FloatParameter(i, _rnboObject));
			}
		}
	}

	_syncParamInterface = _rnboObject.createParameterInterface(ParameterEventInterface::NotThreadSafe, &_syncEventHandler);

#if JUCE_TARGET_HAS_BINARY_DATA
	// Read the preset file, if available
	try  {
		const char *presetData = nullptr;
		int presetDataSize = 0;
		presetData = BinaryData::getNamedResource("presets_json", presetDataSize);
		if (presetDataSize > 0) {
			juce::String s = juce::String(presetData, (size_t) presetDataSize);
			_presetList = new PresetList(s.toStdString());
		}
	} catch (std::exception& e) {
		std::cerr << "exception reading presets json " << e.what() << std::endl;
	}

	try {
		// Read the datarefs file in the same way
		const char *dependenciesData = nullptr;
		int dependenciesDataSize = 0;

		dependenciesData = BinaryData::getNamedResource("dependencies_json", dependenciesDataSize);
		if (dependenciesDataSize > 0) {
			juce::String s = juce::String(dependenciesData, (size_t) dependenciesDataSize);
			_datarefList = new DataRefList(s.toStdString());

			// Create a format manager--we'll need it later
			AudioFormatManager formatManager;
			formatManager.registerBasicFormats();

			// Go through the JUCE binary resources, and make an index on the file name
			juce::HashMap<String, String> dependencyMap;
			for (int i = 0; i < BinaryData::namedResourceListSize; i++) {
				dependencyMap.set(BinaryData::originalFilenames[i],
								  BinaryData::namedResourceList[i]);
			}

			// Now load whatever local dependencies you can
			for (size_t i = 0; i < _datarefList->size(); i++) {
				std::string name = _datarefList->datarefIdAtIndex(i);
				std::string location = _datarefList->datarefLocationAtIndex(i);
				RNBO::DataRefType type = _datarefList->datarefTypeAtIndex(i);

				// TODO: Handle remote URL resources
				if (type == RNBO::DataRefType::URL && location.rfind("file://", 0) != 0)
					continue;

				// Get the filename from the path
				// JUCE File needs the location to start with a ./ if it's a relative path
				File temp = File::getCurrentWorkingDirectory().getChildFile (location);
				String filename = temp.getFileName();

				// Load the resource data
				String resourceName = dependencyMap[filename];
				if (resourceName.length() == 0) continue;
				const char *resourceData = nullptr;
				int resourceDataSize = 0;
				resourceData = BinaryData::getNamedResource(resourceName.getCharPointer(), resourceDataSize);
				if (resourceDataSize == 0) continue;

				std::unique_ptr<MemoryInputStream> memoryStream = make_unique<MemoryInputStream>(resourceData, static_cast<size_t>(resourceDataSize), false);
				AudioFormatReader* reader = formatManager.createReaderFor (std::move(memoryStream));
				if (reader) {
					AudioBuffer<float> buffer;
					buffer.setSize((int) reader->numChannels, (int) reader->lengthInSamples);
					reader->read(&buffer, 0, (int)reader->lengthInSamples, 0, true, true);

					size_t samps = static_cast<size_t>(reader->numChannels * reader->lengthInSamples);
					std::shared_ptr<std::vector<float>> data = std::make_shared<std::vector<float>>(samps);

					// interleave
					// TODO: Handle other sample formats
#if 1
					juce::AudioDataConverters::interleaveSamples(buffer.getArrayOfReadPointers(), &data->front(), static_cast<int>(reader->lengthInSamples), static_cast<int>(reader->numChannels));
#else
					using SourceFormat = AudioData::Format<AudioData::Float32, AudioData::NativeEndian>;
					using DestFormat = AudioData::Format<AudioData::Float32, AudioData::NativeEndian>;
					auto sourceFormat = AudioData::NonInterleavedSource<SourceFormat> { buffer.getArrayOfReadPointers(), (int)reader->numChannels };
					auto destFormat = AudioData::InterleavedDest<DestFormat> { &data->front(),   (int)reader->numChannels };
					AudioData::interleaveSamples(sourceFormat, destFormat, (int) reader->lengthInSamples);
#endif

					RNBO::Float32AudioBuffer bufferType(reader->numChannels, reader->sampleRate);
					_rnboObject.setExternalData(name.c_str(), reinterpret_cast<char *>(&data->front()), samps * sizeof(float), bufferType , [data](RNBO::ExternalDataId, char*) mutable {
							//TODO: if we ever allow for loading datarefs after the plugin is loaded, we need to move the dealloc out of the audio thread
							//see RNBOOSCQueryRunner

							//hold onto shared_ptr until rnbo stops using it
							data.reset();
							});
				} else {
					std::cerr << "failed to load dataref " << name << std::endl;
				}
			}
		}
	} catch (std::exception& e) {
		std::cerr << "exception reading datarefs " << e.what() << std::endl;
	}
#endif // HAS_DEPENDENCIES
}

JuceAudioProcessor::~JuceAudioProcessor()
{
	if (_presetList) {
		delete _presetList;
		_presetList = nullptr;
	}

	if (_datarefList) {
		delete _datarefList;
		_datarefList = nullptr;
	}
}

#ifdef JUCE_STATIC_PLUGIN
	extern "C" const char * JuceStatic_Plugin_Name();
#endif

//==============================================================================
const juce::String JuceAudioProcessor::getName() const
{
#ifndef JUCE_STATIC_PLUGIN
		// Perhaps we should get the name from the generated code via some call?
	return "RNBO Plugin";
#else
	return juce::String(JuceStatic_Plugin_Name());
#endif
}

void JuceAudioProcessor::handleParameterEvent(const ParameterEvent& event)
{
	// Engine might have parameters than aren't exposed to JUCE
	// so we need to filter out any parameter events that are not in our _rnboParamIndexToJuceParamIndex
	auto it = _rnboParamIndexToJuceParamIndex.find(event.getIndex());
	if (it != _rnboParamIndexToJuceParamIndex.end()) {
		// we need to normalize the parameter value
		ParameterValue normalizedValue = _rnboObject.convertToNormalizedParameterValue(event.getIndex(), event.getValue());
		const auto param = getParameters()[it->second];
		if (_isInStartup || _isSettingPresetAsync) {
			param->setValue((float)normalizedValue);
		}
		else {
			param->beginChangeGesture();
			param->setValueNotifyingHost((float)normalizedValue);
			param->endChangeGesture();
		}
	}
}

void JuceAudioProcessor::handleStartupEvent(const RNBO::StartupEvent& event)
{
	_isInStartup = event.getType() == RNBO::StartupEvent::Begin;
}

void JuceAudioProcessor::handlePresetEvent(const RNBO::PresetEvent& event)
{
	if (event.getType() == RNBO::PresetEvent::SettingBegin) {
		_isSettingPresetAsync = true;
	}
	else if (event.getType() == RNBO::PresetEvent::SettingEnd) {
		_isSettingPresetAsync = false;
	}
}

void JuceAudioProcessor::handleAsyncUpdate()
{
	drainEvents();
}

bool JuceAudioProcessor::acceptsMidi() const
{
	return _rnboObject.getNumMidiInputPorts() > 0;
}

bool JuceAudioProcessor::producesMidi() const
{
	return _rnboObject.getNumMidiOutputPorts() > 0;
}

bool JuceAudioProcessor::isMidiEffect() const
{
#if JucePlugin_IsMidiEffect
	return true;
#else
	return false;
#endif
}


bool JuceAudioProcessor::silenceInProducesSilenceOut() const
{
	return false;
}

double JuceAudioProcessor::getTailLengthSeconds() const
{
	return 0.0;
}

int JuceAudioProcessor::getNumPrograms()
{
	// NB: some hosts don't cope very well if you tell them there are 0
	// so this should be at least 1, even if you're not really implementing programs.
	if (!_presetList) {
		return 1;
	} else {
		return (int) _presetList->size();
	}
}

int JuceAudioProcessor::getCurrentProgram()
{
	return _currentPresetIdx;
}

void JuceAudioProcessor::setCurrentProgram (int index)
{
	if (_presetList) {
		_currentPresetIdx = index;
				if (index >= 0) {
					UniquePresetPtr preset = _presetList->presetAtIndex(static_cast<size_t>(index));
					_rnboObject.setPreset(std::move(preset));
				}
	}
}

const juce::String JuceAudioProcessor::getProgramName (int index)
{
    if (!_presetList) {
        return juce::String();
    } else {
        std::string name = _presetList->presetNameAtIndex((size_t)index);
        return juce::String(name);
    }
}

void JuceAudioProcessor::changeProgramName (int index, const String& newName)
{
	RNBO_UNUSED(index)
	RNBO_UNUSED(newName)
	// Can't do it
}

//==============================================================================

void JuceAudioProcessor::prepareToPlay(double sampleRate, int estimatedSamplesPerBlock)
{
	_rnboObject.prepareToProcess(sampleRate, static_cast<Index>(estimatedSamplesPerBlock));
}

void JuceAudioProcessor::releaseResources()
{
}

bool JuceAudioProcessor::isBusesLayoutSupported (const BusesLayout& layouts) const
{
	#if JucePlugin_IsMidiEffect
		return true;
	#endif
	return static_cast<Index>(layouts.getMainInputChannels()) == _rnboObject.getNumInputChannels() && static_cast<Index>(layouts.getMainOutputChannels()) == _rnboObject.getNumOutputChannels();
}

void JuceAudioProcessor::processBlock (AudioSampleBuffer& buffer, juce::MidiBuffer& midiMessages)
{
	_rnboObject.prepareToProcess(getSampleRate(), static_cast<Index>(buffer.getNumSamples()));

	// fill midi input
	TimeConverter timeConverter(_rnboObject.getSampleRate(), _rnboObject.getCurrentTime());

	_midiInput.clear();  // make sure midi input starts clear
	for (auto meta: midiMessages)
	{
		MillisecondTime time = timeConverter.convertSampleOffsetToMilliseconds(meta.samplePosition);
		_midiInput.addEvent(MidiEvent(time, 0, meta.data, (Index)meta.numBytes));
	}

	_rnboObject.process(buffer.getArrayOfWritePointers(), static_cast<Index>(buffer.getNumChannels()),
						buffer.getArrayOfWritePointers(), static_cast<Index>(buffer.getNumChannels()),
						static_cast<Index>(buffer.getNumSamples()),
						&_midiInput, &_midiOutput);

	// consume midi output
	midiMessages.clear();		// clear the input that we consumed above so juce doesn't get confused
	if (!_midiOutput.empty()) {
		std::for_each(_midiOutput.begin(),
					  _midiOutput.end(),
					  [&timeConverter, &midiMessages](const MidiEvent& ev) {
						  int sampleNumber = timeConverter.convertMillisecondsToSampleOffset(ev.getTime());
						  auto midiMessage = MidiMessage(ev.getData(), (int)ev.getLength());
						  midiMessages.addEvent(midiMessage, sampleNumber);
					  });
		_midiOutput.clear();
	}
}

//==============================================================================
bool JuceAudioProcessor::hasEditor() const
{
	return true;
}

AudioProcessorEditor* JuceAudioProcessor::createEditor()
{
	return new RNBOAudioProcessorEditor(this, _rnboObject);
}

//==============================================================================
void JuceAudioProcessor::getStateInformation (MemoryBlock& destData)
{
	auto rnboPreset = _rnboObject.getPresetSync();
	auto rnboPresetStr = RNBO::convertPresetToJSON(*rnboPreset);
	MemoryOutputStream stream(destData, false);
	stream.writeString(rnboPresetStr);
}

void JuceAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
	String rnboPresetStr = String::createStringFromData (data, sizeInBytes);
	auto rnboPreset = RNBO::convertJSONToPreset(rnboPresetStr.toStdString());
	_rnboObject.setPresetSync(std::move(rnboPreset));
}

void JuceAudioProcessor::eventsAvailable()
{
	this->triggerAsyncUpdate();
}

void JuceAudioProcessor::SyncEventHandler::handleParameterEvent(const RNBO::ParameterEvent& event)
{
	if (_isSettingPresetSync) {
		_owner.handleParameterEvent(event);
	}
}

void JuceAudioProcessor::SyncEventHandler::handlePresetEvent(const PresetEvent& event)
{
	if (event.getType() == PresetEvent::SettingBegin) {
		_isSettingPresetSync = true;
	}
	else if (event.getType() == PresetEvent::SettingEnd) {
		_isSettingPresetSync = false;
	}
}


} // namespace RNBO

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
	return new RNBO::JuceAudioProcessor();
}
